<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Xác Thực KYC - Camera và Quay Video</title>
  <style>
    body {
      font-family: sans-serif;
      text-align: center;
      padding: 20px;
    }

    video, canvas {
      width: 100%;
      max-width: 400px;
      border-radius: 12px;
      margin-top: 20px;
      background: black;
      transform: scaleX(-1); /* Xoay gương */
    }

    button {
      padding: 10px 20px;
      margin: 10px 5px;
      font-size: 16px;
      cursor: pointer;
    }
  </style>
</head>
<body>
  <h2>Xác thực KYC</h2>
  <button id="startCamera">Bật camera</button>
  <button id="startRecord" disabled>Bắt đầu quay</button>
  <button id="stopRecord" disabled>Dừng quay</button>
  <br />
  <video id="video" autoplay muted playsinline></video>
  <canvas id="overlay" width="400" height="300"></canvas>
  <br />
  <a id="downloadLink" style="display:none;" download="kyc-record.mp4">Tải video về</a>

  <!-- Load face-api.js library from CDN -->
  <script defer src="https://cdn.jsdelivr.net/npm/face-api.js"></script>

  <script>
    const video = document.getElementById('video');
    const startCameraBtn = document.getElementById('startCamera');
    const startRecordBtn = document.getElementById('startRecord');
    const stopRecordBtn = document.getElementById('stopRecord');
    const downloadLink = document.getElementById('downloadLink');
    const canvas = document.getElementById('overlay');
    const ctx = canvas.getContext('2d');

    let stream;
    let mediaRecorder;
    let recordedChunks = [];

    // Load face-api.js models
    Promise.all([
      faceapi.nets.tinyFaceDetector.loadFromUri('/models'), // Make sure this is where your models are hosted
      faceapi.nets.faceLandmark68Net.loadFromUri('/models'),
      faceapi.nets.faceRecognitionNet.loadFromUri('/models')
    ]).then(startVideo);

    startCameraBtn.addEventListener('click', async () => {
      try {
        stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: false });
        video.srcObject = stream;
        await video.play();

        startRecordBtn.disabled = false;
        console.log("Camera đã bật");
      } catch (err) {
        alert("Không thể truy cập camera: " + err.message);
        console.error(err);
      }
    });

    startRecordBtn.addEventListener('click', () => {
      if (!stream) return;

      recordedChunks = [];
      mediaRecorder = new MediaRecorder(stream);

      mediaRecorder.ondataavailable = (e) => {
        if (e.data.size > 0) recordedChunks.push(e.data);
      };

      mediaRecorder.onstop = () => {
        const blob = new Blob(recordedChunks, { type: 'video/mp4' });
        const url = URL.createObjectURL(blob);

        downloadLink.href = url;
        downloadLink.style.display = 'inline';
        downloadLink.textContent = "Tải video về";

        console.log("Video blob:", blob);
      };

      mediaRecorder.start();
      console.log("Bắt đầu quay");

      startRecordBtn.disabled = true;
      stopRecordBtn.disabled = false;
      downloadLink.style.display = 'none';
    });

    stopRecordBtn.addEventListener('click', () => {
      if (mediaRecorder && mediaRecorder.state !== "inactive") {
        mediaRecorder.stop();
        console.log("Dừng quay");
        startRecordBtn.disabled = false;
        stopRecordBtn.disabled = true;
      }
    });

    async function startVideo() {
      video.onloadedmetadata = () => {
        detectLoop();
      };
    }

    async function detectLoop() {
      const options = new faceapi.TinyFaceDetectorOptions();

      setInterval(async () => {
        const detections = await faceapi.detectAllFaces(video, options);

        ctx.clearRect(0, 0, canvas.width, canvas.height);
        faceapi.draw.drawDetections(canvas, detections);

        if (detections.length > 0) {
          const box = detections[0].box;
          console.log("Vị trí mặt:", box);
        }
      }, 300);
    }
  </script>
</body>
</html>
